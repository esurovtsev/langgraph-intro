{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangGraph API\n",
    "\n",
    "Tell about server part of LangGraph Studio and prefered approach to build graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': 'b7480eb0-6390-53a5-9bc4-29bf27cbd1c4',\n",
       "  'graph_id': 'financial_advisor',\n",
       "  'created_at': '2025-02-07T10:30:03.580904+00:00',\n",
       "  'updated_at': '2025-02-07T10:30:03.580904+00:00',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'version': 1,\n",
       "  'name': 'financial_advisor'},\n",
       " {'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7',\n",
       "  'graph_id': 'chatbot',\n",
       "  'created_at': '2025-02-01T11:56:26.459428+00:00',\n",
       "  'updated_at': '2025-02-01T11:56:26.459428+00:00',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'version': 1,\n",
       "  'name': 'chatbot'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "URL = \"http://localhost:61693\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()\n",
    "assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b7480eb0-6390-53a5-9bc4-29bf27cbd1c4'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants[0][\"assistant_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
       "   'additional_kwargs': {},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': 'd4993bf8-e2fa-4cae-b949-f5215351ebc0',\n",
       "   'example': False},\n",
       "  {'content': \"Sure, I can help with that! Could you provide more details about the API you're working with? Specifically, what kind of responses are you receiving, and what issues are you facing while handling them?\",\n",
       "   'additional_kwargs': {'refusal': None},\n",
       "   'response_metadata': {'token_usage': {'completion_tokens': 41,\n",
       "     'prompt_tokens': 92,\n",
       "     'total_tokens': 133,\n",
       "     'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "      'audio_tokens': 0,\n",
       "      'reasoning_tokens': 0,\n",
       "      'rejected_prediction_tokens': 0},\n",
       "     'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "    'system_fingerprint': 'fp_72ed7ab54c',\n",
       "    'finish_reason': 'stop',\n",
       "    'logprobs': None},\n",
       "   'type': 'ai',\n",
       "   'name': None,\n",
       "   'id': 'run-a90e4cf4-2fb7-41e2-915c-583f22352207-0',\n",
       "   'example': False,\n",
       "   'tool_calls': [],\n",
       "   'invalid_tool_calls': [],\n",
       "   'usage_metadata': {'input_tokens': 92,\n",
       "    'output_tokens': 41,\n",
       "    'total_tokens': 133,\n",
       "    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "    'output_token_details': {'audio': 0, 'reasoning': 0}}}],\n",
       " 'question': 'Hi, I’m working on a Python project, and I’m stuck with handling API responses.',\n",
       " 'answer': \"Sure, I can help with that! Could you provide more details about the API you're working with? Specifically, what kind of responses are you receiving, and what issues are you facing while handling them?\",\n",
       " 'summary': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "final_state = await client.runs.wait(\n",
    "    thread_id=thread[\"thread_id\"],\n",
    "    assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\",\n",
    "    input={\"question\": \"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\"}\n",
    ")\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You mentioned that you are working on a Python project and are stuck with handling API responses. If you need further assistance or have specific questions about this topic, feel free to share!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = await client.runs.wait(\n",
    "    thread_id=thread[\"thread_id\"],\n",
    "    assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\",\n",
    "    input={\"question\": \"Sorry what was my previous question?\"}\n",
    ")\n",
    "\n",
    "final_state[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
       "   'additional_kwargs': {},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': '89f67be7-d212-4145-b85f-39a51f25e31b',\n",
       "   'example': False},\n",
       "  {'content': 'Parsing JSON responses can be tricky, especially if the structure varies. To handle this more robustly, consider the following tips:\\n\\n1. **Use `try` and `except` Blocks:** Wrap your JSON parsing code in `try` and `except` blocks to catch any exceptions if the structure doesn\\'t match your expectations.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"name\": \"John\", \"age\": 30}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       print(data[\\'name\\'])  # Access expected keys\\n   except KeyError as e:\\n       print(f\"Key error: {e}\")\\n   except json.JSONDecodeError:\\n       print(\"Failed to decode JSON.\")\\n   ```\\n\\n2. **Validate the JSON Structure:** Before accessing specific keys, check if they exist.\\n\\n   ```python\\n   if \\'name\\' in data:\\n       print(data[\\'name\\'])\\n   else:\\n       print(\"Expected key \\'name\\' not found.\")\\n   ```\\n\\n3. **Use `get()` Method:** This method allows you to attempt to retrieve a value, providing a default if the key doesn’t exist.\\n\\n   ```python\\n   name = data.get(\\'name\\', \\'Default Name\\')  # Will return \\'Default Name\\' if \\'name\\' key is not found\\n   ```\\n\\n4. **Log Unexpected Structures:** If the API response structure often changes, consider logging the entire response when it doesn\\'t match your expected structure to help you adjust your code.\\n\\nIf you have a specific JSON response example that’s causing issues, feel free to share it for more tailored assistance!',\n",
       "   'additional_kwargs': {'refusal': None},\n",
       "   'response_metadata': {'token_usage': {'completion_tokens': 326,\n",
       "     'prompt_tokens': 214,\n",
       "     'total_tokens': 540,\n",
       "     'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "      'audio_tokens': 0,\n",
       "      'reasoning_tokens': 0,\n",
       "      'rejected_prediction_tokens': 0},\n",
       "     'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "    'system_fingerprint': 'fp_72ed7ab54c',\n",
       "    'finish_reason': 'stop',\n",
       "    'logprobs': None},\n",
       "   'type': 'ai',\n",
       "   'name': None,\n",
       "   'id': 'run-2c06c96f-5e4a-4fc6-951f-557a31938dad-0',\n",
       "   'example': False,\n",
       "   'tool_calls': [],\n",
       "   'invalid_tool_calls': [],\n",
       "   'usage_metadata': {'input_tokens': 214,\n",
       "    'output_tokens': 326,\n",
       "    'total_tokens': 540,\n",
       "    'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "    'output_token_details': {'audio': 0, 'reasoning': 0}}}],\n",
       " 'question': 'Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.',\n",
       " 'answer': 'Parsing JSON responses can be tricky, especially if the structure varies. To handle this more robustly, consider the following tips:\\n\\n1. **Use `try` and `except` Blocks:** Wrap your JSON parsing code in `try` and `except` blocks to catch any exceptions if the structure doesn\\'t match your expectations.\\n\\n   ```python\\n   import json\\n\\n   response = \\'{\"name\": \"John\", \"age\": 30}\\'  # Example response\\n   try:\\n       data = json.loads(response)\\n       print(data[\\'name\\'])  # Access expected keys\\n   except KeyError as e:\\n       print(f\"Key error: {e}\")\\n   except json.JSONDecodeError:\\n       print(\"Failed to decode JSON.\")\\n   ```\\n\\n2. **Validate the JSON Structure:** Before accessing specific keys, check if they exist.\\n\\n   ```python\\n   if \\'name\\' in data:\\n       print(data[\\'name\\'])\\n   else:\\n       print(\"Expected key \\'name\\' not found.\")\\n   ```\\n\\n3. **Use `get()` Method:** This method allows you to attempt to retrieve a value, providing a default if the key doesn’t exist.\\n\\n   ```python\\n   name = data.get(\\'name\\', \\'Default Name\\')  # Will return \\'Default Name\\' if \\'name\\' key is not found\\n   ```\\n\\n4. **Log Unexpected Structures:** If the API response structure often changes, consider logging the entire response when it doesn\\'t match your expected structure to help you adjust your code.\\n\\nIf you have a specific JSON response example that’s causing issues, feel free to share it for more tailored assistance!',\n",
       " 'summary': 'The user is working on a Python project and is struggling with parsing JSON responses from APIs, noting that unexpected structures often break their code. They requested help with specific issues related to this, particularly how to handle varying JSON structures effectively. The conversation included strategies such as using `try` and `except` blocks for error handling, checking for key existence, utilizing the `get()` method for safer access, and logging unexpected structures for future reference. They also asked for clarification on their previous question.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = await client.runs.wait(\n",
    "    thread_id=thread[\"thread_id\"],\n",
    "    assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\",\n",
    "    input={\"question\": \"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\"}\n",
    ")\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Observe the difference between constructing graph manually & using LangGraph Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define chatbot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, RemoveMessage\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY environment variable must be set\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# System message\n",
    "chatbot_system_message = SystemMessage(content=(\"\"\"\n",
    "You are a helpful and knowledgeable chatbot assistant. \n",
    "Your goal is to provide clear and accurate answers to user questions based on the information they provide. \n",
    "Stay focused, concise, and ensure your responses are relevant to the context of the conversation. \n",
    "If you don’t have enough information, ask for clarification.”\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def chatbot(state: MessagesState) -> MessagesState:\n",
    "    response = llm.invoke([chatbot_system_message] + state[\"messages\"]);\n",
    "    return MessagesState(messages = [response])\n",
    "\n",
    "\n",
    "# Graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(chatbot)\n",
    "\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "workflow.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming modes:\n",
    "\n",
    "- updates (exposes only new data)\n",
    "- values (always shows the whole state)\n",
    "- messages\n",
    "- debug\n",
    "- custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream_mode=updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='I can help with that! What specific issues are you encountering with handling API responses in your Python project? Are you having trouble parsing the response, dealing with errors, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 92, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-78db9f95-83f8-41f1-b779-d667497c1b52-0', usage_metadata={'input_tokens': 92, 'output_tokens': 38, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"updates\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You mentioned that you are working on a Python project and that you’re stuck with handling API responses. How can I assist you further with that?\n"
     ]
    }
   ],
   "source": [
    "user_input = HumanMessage(content=\"Sorry what was my previous question?\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"updates\"):\n",
    "    for m in event['chatbot']['messages']:\n",
    "        m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream_mode=values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='0b8d3a53-21b9-4b06-928f-a594512a5bdf')]}\n",
      "{'messages': [HumanMessage(content='Hi, I’m working on a Python project, and I’m stuck with handling API responses.', additional_kwargs={}, response_metadata={}, id='0b8d3a53-21b9-4b06-928f-a594512a5bdf'), AIMessage(content='I can help with that! Can you provide more details about the API you’re working with, the issues you’re facing, and what you’ve tried so far?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 92, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-40992345-b3c1-47dd-ac36-5ced5157e99e-0', usage_metadata={'input_tokens': 92, 'output_tokens': 34, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with that! Can you provide more details about the API you’re working with, the issues you’re facing, and what you’ve tried so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with that! Can you provide more details about the API you’re working with, the issues you’re facing, and what you’ve tried so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I’m working on a Python project, and I’m stuck with handling API responses.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! To help you effectively, could you tell me:\n",
      "\n",
      "1. Which API you are using?\n",
      "2. What specific issues are you encountering with the responses (e.g., parsing JSON, handling errors, etc.)?\n",
      "3. Any relevant code snippets you've tried?\n",
      "\n",
      "This information will help me assist you better!\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming deeper (updates inside Node) - a.k.a. \"streaming LLM tokens from a specific node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='I', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' help', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' What', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' issue', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' facing', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' handling', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' API', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' responses', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' your', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' Python', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' project', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' Are', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' having', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' trouble', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' requests', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' parsing', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' response', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' something', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content=' else', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c'}, id='run-6b71448d-8da0-4513-9301-bcbf55255997'), {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'checkpoint_ns': 'chatbot:ecabe036-7295-522c-495c-54790fc26824', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None})\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "for event in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"messages\"):\n",
    "    print(event)\n",
    "\n",
    "# so we have a message with content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing JSON responses can indeed be tricky if the structure varies. Here are some general tips to handle this:\n",
      "\n",
      "1. **Use `try-except` Blocks**: This can help catch any exceptions that occur when accessing nested keys that might not exist.\n",
      "\n",
      "   ```python\n",
      "   import requests\n",
      "\n",
      "   response = requests.get('your_api_endpoint')\n",
      "   data = response.json()\n",
      "\n",
      "   try:\n",
      "       value = data['expected_key']\n",
      "   except KeyError:\n",
      "       print(\"Key not found, handle it appropriately.\")\n",
      "   ```\n",
      "\n",
      "2. **Check for Key Existence**: Before accessing a nested key, check if it exists using `dict.get()` or the `in` keyword.\n",
      "\n",
      "   ```python\n",
      "   if 'expected_key' in data:\n",
      "       value = data['expected_key']\n",
      "   else:\n",
      "       print(\"Key not found\")\n",
      "   ```\n",
      "\n",
      "3. **Use Default Values**: The `get()` method allows you to set a default value if the key does not exist.\n",
      "\n",
      "   ```python\n",
      "   value = data.get('expected_key', 'default_value')\n",
      "   ```\n",
      "\n",
      "4. **Inspect the Structure**: Print the entire response or part of it to understand its structure.\n",
      "\n",
      "   ```python\n",
      "   print(data)  # or print(data.keys()) for top-level keys\n",
      "   ```\n",
      "\n",
      "5. **Nested Structures**: If you're working with nested dictionaries or lists, use additional checks for each level.\n",
      "\n",
      "Here’s a more complex example handling a nested structure:\n",
      "\n",
      "```python\n",
      "response = requests.get('your_api_endpoint')\n",
      "data = response.json()\n",
      "\n",
      "# Assuming the response is {\"user\": {\"id\": 1, \"info\": {\"name\": \"John\"}}}\n",
      "user_info = data.get('user', {})\n",
      "user_id = user_info.get('id', None)\n",
      "user_name = user_info.get('info', {}).get('name', 'Unknown')\n",
      "\n",
      "print(f\"User ID: {user_id}, Name: {user_name}\")\n",
      "```\n",
      "\n",
      "If you need help with a specific JSON structure or error, feel free to share that!"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "user_input = HumanMessage(content=\"Ahh, yeah right! So I’m mostly struggling with parsing JSON responses. Sometimes the structure isn’t what I expect, and it breaks my code.\")\n",
    "for msg, metadata in graph.stream({\"messages\": [user_input]}, config, stream_mode=\"messages\"):\n",
    "    if (metadata['langgraph_node'] == 'chatbot'):\n",
    "        print(msg.content, end=\"\")\n",
    "\n",
    "# same style of outputing data as in chat app (a token by token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming with LangGraph API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "URL = \"http://localhost:61693\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "assistants = await client.assistants.search()\n",
    "assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = await client.threads.create()\n",
    "\n",
    "input_message = HumanMessage(content=\"Hi, I’m working on a Python project, and I’m stuck with handling API responses.\")\n",
    "\n",
    "async for part in client.runs.stream(\n",
    "        thread[\"thread_id\"], \n",
    "        assistant_id=\"8a4ac7a4-50eb-5206-98cc-4a72345cb1f7\", \n",
    "        input={\"messages\": [input_message]}, \n",
    "        stream_mode=\"messages\"):\n",
    "    print(part)\n",
    "\n",
    "# check event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Should I invest in Tesla stocks?\")\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "            thread[\"thread_id\"], \n",
    "            assistant_id=\"b7480eb0-6390-53a5-9bc4-29bf27cbd1c4\", \n",
    "            input={\"messages\": [input_message]}, \n",
    "            stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "\n",
    "# display content only with convert_to_messages util"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
