{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update state after breakpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redefine financial advicer graph (from 03_agent.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Defining Tools\n",
    "##################################################################################\n",
    "\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Binding tools to the LLM\n",
    "##################################################################################\n",
    "\n",
    "# Create tool bindings with additional attributes\n",
    "lookup_stock = Tool.from_function(\n",
    "    func=lookup_stock_symbol,\n",
    "    name=\"lookup_stock_symbol\",\n",
    "    description=\"Converts a company name to its stock symbol using a financial API.\",\n",
    "    return_direct=False  # Return result to be processed by LLM\n",
    ")\n",
    "\n",
    "fetch_stock = Tool.from_function(\n",
    "    func=fetch_stock_data_raw,\n",
    "    name=\"fetch_stock_data_raw\",\n",
    "    description=\"Fetches comprehensive stock data including general info and historical market data for a given stock symbol.\",\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "toolbox = [lookup_stock, fetch_stock]\n",
    "\n",
    "# OPENAI_API_KEY environment variable must be set\n",
    "simple_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = simple_llm.bind_tools(toolbox)\n",
    "\n",
    "\n",
    "# Defining Agent's node\n",
    "##################################################################################\n",
    "\n",
    "# System message\n",
    "assistant_system_message = SystemMessage(content=(\"\"\"\n",
    "You are a professional financial assistant specializing in stock market analysis and investment strategies. \n",
    "Your role is to analyze stock data and provide **clear, decisive recommendations** that users can act on, \n",
    "whether they already hold the stock or are considering investing.\n",
    "\n",
    "You have access to a set of tools that can provide the data you need to analyze stocks effectively. \n",
    "Use these tools to gather relevant information such as stock symbols, current prices, historical trends, \n",
    "and key financial indicators. Your goal is to leverage these resources efficiently to generate accurate, \n",
    "actionable insights for the user.\n",
    "\n",
    "Your responses should be:\n",
    "- **Concise and direct**, summarizing only the most critical insights.\n",
    "- **Actionable**, offering clear guidance on whether to buy, sell, hold, or wait for better opportunities.\n",
    "- **Context-aware**, considering both current holders and potential investors.\n",
    "- **Free of speculation**, relying solely on factual data and trends.\n",
    "- **do not forget** to provide stock name in the report, so it's clear which stock is being recommended.\n",
    "\n",
    "### Response Format:\n",
    "1. **Recommendation:** Buy, Sell, Hold, or Wait.\n",
    "2. **Key Insights:** Highlight critical trends and market factors that influence the decision.\n",
    "3. **Suggested Next Steps:** What the user should do based on their current position.\n",
    "\n",
    "If the user does not specify whether they own the stock, provide recommendations for both potential buyers and current holders. Ensure your advice considers valuation, trends, and market sentiment.\n",
    "\n",
    "Your goal is to help users make informed financial decisions quickly and confidently.\n",
    "\"\"\"))\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([assistant_system_message] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Defining Graph\n",
    "##################################################################################\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(toolbox))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's set breakpoints before Assistant node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new conversation\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# define intiial user request\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Should I invest in Tesla stocks?\")}\n",
    "\n",
    "# run the graph and stream in values mode\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "state = graph.get_state(thread)\n",
    "pprint(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update graph state (add a new message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread, {\"messages\": [HumanMessage(content=\"No sorry, I changed my mind. I would be more interested in Apple stocks!\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.get_state(thread).values['messages']\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We stopped again on Assistant node, let's resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change graph state in Studio\n",
    "\n",
    "1) set a break point\n",
    "\n",
    "2) trigger the update\n",
    "\n",
    "- Should I invest in Tesla stocks?\n",
    "- No sorry, I changed my mind. I would be more interested in Apple stocks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "URL = \"http://localhost:59804\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "assistants = await client.assistants.search()\n",
    "assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a chat with a breakpoint before \"Assistant\" node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Should I invest in Tesla stocks?\")\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "            thread[\"thread_id\"], \n",
    "            assistant_id=\"b7480eb0-6390-53a5-9bc4-29bf27cbd1c4\", \n",
    "            input={\"messages\": [input_message]}, \n",
    "            stream_mode=\"values\",\n",
    "            interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    messages = event.data.get('messages', None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = await client.threads.get_state(thread['thread_id'])\n",
    "current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's grab the latest message and update it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message = current_state['values']['messages'][-1]\n",
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the message content keeping the `id` the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message['content'] = \"No sorry, I changed my mind. I would be more interested in Apple stocks!\"\n",
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the state (with message replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.threads.update_state(thread['thread_id'], {\"messages\": last_message})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in client.runs.stream(\n",
    "            thread[\"thread_id\"], \n",
    "            assistant_id=\"b7480eb0-6390-53a5-9bc4-29bf27cbd1c4\", \n",
    "            input=None, \n",
    "            stream_mode=\"values\",\n",
    "            interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    messages = event.data.get('messages', None)\n",
    "    if messages:\n",
    "        print(f\"\\n\\n{convert_to_messages(messages)[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A node with human feedback\n",
    "\n",
    "A simple way to use human feedback is to create a human_feedback node that collects user input. This helps us gather feedback at a specific point in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state: MessagesState):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Defining Graph\n",
    "##################################################################################\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(toolbox))\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update state as user_feedback node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "initial_input = {\"messages\": \"Should I invest in Tesla stocks?\"}\n",
    "\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "user_input = input(\"Update the state:\")\n",
    "\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
